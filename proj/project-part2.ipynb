{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f12ffa9b",
   "metadata": {},
   "source": [
    "<img src=\"data6.png\" style=\"width: 15%; float: right; padding: 1%; margin-right: 2%;\"/>\n",
    "\n",
    "# Final Project Part 2\n",
    "\n",
    "## Data 6, Fall 2024\n",
    "\n",
    "Welcome to the final project for Data 6! You can have up to one partner for the project. Only one partner should submit on behalf of the entire group on gradescope (submit and add group member). This part of the project is due December 9th at 11:00 PM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbffeafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Using cached openai-1.55.0-py3-none-any.whl (389 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /srv/conda/lib/python3.11/site-packages (from openai) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /srv/conda/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /srv/conda/lib/python3.11/site-packages (from openai) (0.27.2)\n",
      "Collecting jiter<1,>=0.4.0\n",
      "  Using cached jiter-0.7.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /srv/conda/lib/python3.11/site-packages (from openai) (1.10.8)\n",
      "Requirement already satisfied: sniffio in /srv/conda/lib/python3.11/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /srv/conda/lib/python3.11/site-packages (from openai) (4.66.2)\n",
      "Collecting typing-extensions<5,>=4.11\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /srv/conda/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: certifi in /srv/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /srv/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /srv/conda/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Installing collected packages: typing-extensions, jiter, openai\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.7.0\n",
      "    Uninstalling typing_extensions-4.7.0:\n",
      "      Successfully uninstalled typing_extensions-4.7.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "linearmodels 0.0.0 requires Cython>=3.0.10, which is not installed.\n",
      "linearmodels 0.0.0 requires setuptools-scm[toml]<9.0.0,>=8.0.0, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed jiter-0.7.1 openai-1.55.0 typing-extensions-4.12.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "from datascience import *\n",
    "import numpy as np\n",
    "from IPython.display import YouTubeVideo, HTML, display\n",
    "from ipywidgets import interact, widgets\n",
    "%matplotlib inline\n",
    "%pip install openai #You may see an Error pop up, that's fine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70805cb2-a883-4633-aa96-f873310e4861",
   "metadata": {},
   "source": [
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "\n",
    "# Section 0: Logistical Notes & Setup\n",
    "\n",
    "If you are working with a partner, you'll need some way of storing your intermediate work/sending work to one another. You have a few options:\n",
    "\n",
    "1. (RECOMMENDED): Type up your written responses on a separate Google Document, then transfer the work into this notebook.\n",
    "2. You can send the file by \n",
    "The best way to do this is to send your notebook to one another by clicking File --> Download. Then, you can email that file to your partner, and have them download it on their end. Then, click on the Jupyter icon on the very top left of the screen. That will take you to your home directory. You can then access materials-fa24/proj and upload the file into that directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3105316c-bd21-4e9e-b4fe-d7bcec43751a",
   "metadata": {},
   "source": [
    "\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "# Question 1 â€“ Loading Your Data\n",
    "\n",
    "Go back to your work from Part 1 of the Project. From Question 7 of Part 1, `hand_coded_dataset` should be updated with at least two new columns (if you're working with a partner), with 20 rows.\n",
    "\n",
    "From there, run this line of code to turn your Table into a CSV file: `hand_coded_dataset.to_df().to_csv('hand_coded_data.csv', index = False)`.\n",
    "\n",
    "Once you've done so, click on the Jupyter Notebook icon on the top left of the page:\n",
    "\n",
    "<img src=\"jupyter.png\" style=\"width: 15%; float: center; padding: 1%; margin-right: 2%;\"/>\n",
    "\n",
    "From there, navigate to the `materials-fa24/proj` directory. You should see `hand_coded_data.csv` there now. Amazing!\n",
    "\n",
    "Now, load in your `hand_coded_dataset` as a Table, as well as your `final_dataset` containing the full 1000 rows that you chose from Part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8251e7b7-b91b-4e0b-954c-ebf5bdb997c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Table' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m hand_coded_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mTable\u001b[49m\u001b[38;5;241m.\u001b[39mread_table(\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m) \u001b[38;5;66;03m#LOAD IN YOUR DATA HERE\u001b[39;00m\n\u001b[1;32m      2\u001b[0m full_dataset \u001b[38;5;241m=\u001b[39m Table\u001b[38;5;241m.\u001b[39mread_table(\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m) \u001b[38;5;66;03m#LOAD IN YOUR DATA HERE\u001b[39;00m\n\u001b[1;32m      3\u001b[0m hand_coded_dataset\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Table' is not defined"
     ]
    }
   ],
   "source": [
    "hand_coded_dataset = Table.read_table(...) #LOAD IN YOUR DATA HERE\n",
    "full_dataset = Table.read_table(...) #LOAD IN YOUR DATA HERE\n",
    "hand_coded_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9894022e-8f88-4470-9de5-45fd54519f3f",
   "metadata": {},
   "source": [
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "\n",
    "# Section 1: Exploratory Data Analysis (EDA)\n",
    "\n",
    "Let's continue to get to know our dataset a little more. In Part 1, you did some qualitative analysis on the context of your data, but not much quantitative (numeric-based) analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd2dd7f-cb5f-4ed5-af14-725ff3e56f66",
   "metadata": {},
   "source": [
    "\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "# Question 2 - Word Frequency\n",
    "\n",
    "Let's start by making a dictionary of word frequencies. Using `full_dataset`, create a dictionary `word_counts` that maps all the unique words in all of the text to their corresponding frequencies. For instance, across the 1000 rows, if the word \"thanks\" shows up 50 times, we should have an entry in our dictionary with the key \"thanks\" and the corresponding value 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71853f0b-3a3b-4f4f-9ff7-7cafec4857ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = {}\n",
    "\n",
    "...\n",
    "\n",
    "#This sorts our dictionary based off the corresponding frequency.\n",
    "word_counts = dict(sorted(word_counts.items(), key=lambda item: item[1], reverse = True))\n",
    "\n",
    "#Elizabeth, can you help me calculate what the most frequent word is for each full dataset and note that here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6124b0d-039a-41b4-be45-378ccbdbdf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d4afec-4ab5-42c8-9be2-d5a0f059989b",
   "metadata": {},
   "source": [
    "# Question 3 - Reflection\n",
    "\n",
    "Suppose we try using `word_counts` to get a sense of what people are talking about. In 1-2 sentences, what is a potential downside of this method?\n",
    "\n",
    "Hint: Consider the most frequent words in `word_counts`, and how significant they are."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834abad1-39ed-48bc-8b36-72ea72132121",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6150e12a-5d6f-4cf9-9937-ba69c2e67f80",
   "metadata": {},
   "source": [
    "# Question 4 - TF-IDF\n",
    "\n",
    "To try to get more semantically significant terms (words that carry more meaning), let's compute a TF-IDF score for each word within a Tweet (when we mention Tweet, we're referring to each String containing multiple words within our dataset). TF-IDF stands for term frequency-inverse document frequency. In other words, we will count the frequency of some term (term frequency), and multiply it by the inverse of the number of times that same term appears across the entire dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022f08db-56ae-4b6d-b60a-eb9ce2caab16",
   "metadata": {},
   "source": [
    "You'll start by computing the term frequency, which follows this formula:\n",
    "\n",
    "$$\n",
    "\\text{TF}(w, t) = \\frac{\\text{count}(w, t)}{\\text{total\\_words}(t)}\n",
    "$$\n",
    "\n",
    "**Description**:\n",
    "- `w`: The word being analyzed.\n",
    "- `t`: The specific Tweet you're examining.\n",
    "- `count(w, t)`: The number of occurrences of `w` in Tweet `t`.\n",
    "- `total_words(t)`: The total number of words in Tweet `t`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368391e1-55a3-4e41-9f78-25fad01ad475",
   "metadata": {},
   "source": [
    "Then, you'll calculate the inverse document frequency, following this formula:\n",
    "\n",
    "$$\n",
    "\\text{IDF}(w) = \\log \\left( \\frac{N}{1 + \\text{df}(w, d, c)} \\right)\n",
    "$$\n",
    "\n",
    "**Description**:\n",
    "- `w`: The word being analyzed.\n",
    "- `N`: The total number of Tweets in the dataset (in this case, 1000).\n",
    "- `df(w, d, c)`: The number of Tweets containing the word `w` in the entire dataset `d` when looking at column `c`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76a8e668-d380-4739-abae-3835bca03dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log #log allows us to take the natural log of some value. You can treat log as any other function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbc7967f-16a5-4e3c-b6a2-6bcdf0ba3346",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 12\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m    Returns the number of times that the word w appears in the Tweet t\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m    1\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m count(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhello\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhello hello\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;66;03m#This should pass without Errors\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m count(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhello\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhello\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;66;03m#This should pass without Errors\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def count(w, t):\n",
    "    \"\"\"\n",
    "    Returns the number of times that the word w appears in the Tweet t\n",
    "\n",
    "    >>> word = \"hello\"\n",
    "    >>> tweet = \"hello there friend!\"\n",
    "    >>> count(word, tweet)\n",
    "    1\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "assert count(\"hello\", \"hello hello\") == 2 #This should pass without Errors\n",
    "assert count(\"hello\", \"hello\") == 1 #This should pass without Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e46e968-d089-4144-8b36-1e3c3f1bed36",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 10\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m    Returns the number of words in the Tweet t\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m    3\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m total_words(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhello there friend!\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;66;03m#This should pass without Errors\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def total_words(t):\n",
    "    \"\"\"\n",
    "    Returns the number of words in the Tweet t\n",
    "\n",
    "    >>> tweet = \"hello there friend!\"\n",
    "    >>> total_words(tweet)\n",
    "    3\n",
    "    \"\"\"\n",
    "    pass\n",
    "assert total_words(\"hello there friend!\") == 3 #This should pass without Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfa4d2da-af3b-43bf-b3ce-ed1191880d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df(w, d, c):\n",
    "    \"\"\"\n",
    "    Returns the number of times word w appears in the dataset.\n",
    "\n",
    "    >>> word = \"hello\"\n",
    "    >>> dataset = full_dataset\n",
    "    >>> column_name = \"text\" #This is for the airline tweets dataset\n",
    "    >>> df(word, dataset, column_name)\n",
    "    *We expect some number here*\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "#Elizabeth, can you also find some assertion statements for certain words in each dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fab439-b58c-40fe-803d-af48740a806b",
   "metadata": {},
   "source": [
    "Finally, fill in the function to compute the TF-IDF. As a reminder, here are all the formulas:\n",
    "\n",
    "$$\n",
    "\\text{TF}(w, t) = \\frac{\\text{count}(w, t)}{\\text{total\\_words}(t)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{IDF}(w, d, c) = \\log \\left( \\frac{N}{1 + \\text{df}(w, d, c)} \\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{TF-IDF}(w, t, d, c) = \\text{TF}(w, t) \\times \\text{IDF}(w, d, c)\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "529fcc72-aad4-485b-bf79-52dbcf6f2641",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf(w, t, d, c):\n",
    "    \"\"\"\n",
    "    Compute the tf_idf score for word w within Tweet t.\n",
    "    To compute the inverse document frequency, use column c within dataset d.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "#Elizabeth, can you also find some assertion statements for the intended TF-IDF for each word in each dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8323e1-8c8d-4d74-ba98-4396dcde9fe7",
   "metadata": {},
   "source": [
    "Finally, using `tf_idf`, begin by making a dictionary `word_tf_idf` where the keys are each word in the dataset, and each value is a count of the number of times that particular word has the highest tf_idf score within that tweet.\n",
    "\n",
    "For example, if we have two tweets:\n",
    "\n",
    "\"Hi there friend\"\n",
    "\n",
    "and \n",
    "\n",
    "\"Hi friend\"\n",
    "\n",
    "with the following TF-IDF scores:\n",
    "\n",
    "`{\"Hi\": 1, \"there\": 0.5, \"friend\": 1}`\n",
    "\n",
    "`{\"Hi\": 0.3, \"friend\": 0.1}`\n",
    "\n",
    "we should expect the following dictionary assigned to `word_highest_tf_idf`:\n",
    "\n",
    "`{\"Hi\": 2, \"friend\": 1}`\n",
    "\n",
    "This is because \"Hi\" had the highest TF-IDF score in a tweet twice, and friend had the highest TF-DIF score in a tweet once.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fd12b02-bf20-4706-ab81-c558ec02cb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_highest_tf_idf = {}\n",
    "\n",
    "# Iterate through each tweet in the dataset\n",
    "for text in ...:\n",
    "    # Calculate TF-IDF scores for each word in the tweet\n",
    "    word_scores = {}\n",
    "    for word in text.split(\" \"):\n",
    "        score = ...\n",
    "        word_scores[word] = score\n",
    "    \n",
    "    max_score = max(word_scores.values()) #Calculate the maximum score\n",
    "    \n",
    "    for word, score in word_scores.items():\n",
    "        if score == max_score:\n",
    "            if word not in word_highest_tf_idf:\n",
    "                word_highest_tf_idf[word] = 1\n",
    "            else:\n",
    "                word_highest_tf_idf[word] += 1\n",
    "\n",
    "# Sort the dictionary by the count of times each word was the highest TF-IDF scorer\n",
    "word_highest_tf_idf = dict(sorted(word_highest_tf_idf.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "#Elizabeth, can you help me calculate what the most frequent TF-IDF is for each full dataset and note that here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "451dc66f-d2d7-4a4e-b2d7-c13499d6bfce",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_highest_tf_idf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mword_highest_tf_idf\u001b[49m \u001b[38;5;66;03m#Don't focus as much on the ones with only 1 as their value, as there are a lot of them!\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'word_highest_tf_idf' is not defined"
     ]
    }
   ],
   "source": [
    "word_highest_tf_idf #Don't focus as much on the ones with only 1 as their value, as there are a lot of them!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9aa22ef-2dfb-4be8-b93b-31ad70b2be02",
   "metadata": {},
   "source": [
    "# Question 5 - TF-IDF Reflection\n",
    "\n",
    "How does the TF-IDF value compare to straight up word count in terms of usefulness? Any patterns you're noticing? 3-4 sentences is sufficient for this section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88484d6-ca39-4bc8-bb60-b48697455bcd",
   "metadata": {},
   "source": [
    "REPLACE THIS TEXT WITH YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479c83d0-02e3-4c38-8b2b-76308971e843",
   "metadata": {},
   "source": [
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "\n",
    "# Section 2: Working with APIs\n",
    "\n",
    "An Application Programming Interface (API) allows programmers (people who write code) to access code that other people have written. One large benefit of using APIs is that you don't have to understand how a function is implemented, but just its functionality.\n",
    "\n",
    "An example is your usage of the Numpy module. When you call `np.average`, you can trust that the function will return the mean value of all the values in the Numpy array that was passed in, but you don't need to know exactly how the function is implemented!\n",
    "\n",
    "Most likely, you've used [chatgpt.com](https://chatgpt.com/) in order to access a Large Language Models (LLMs). But now, with our technical skills, we can use an API request to access these LLMs! \n",
    "\n",
    "To start off, we've shared your API key with you on EdStem. This API key allows Open AI to recognize who is using their API, and charge us accordingly. Set your `API_KEY` to be a String of alphanumeric characters that we provide you.\n",
    "\n",
    "**IMPORTANT NOTE: Please DO NOT share your API key outside of this class. We will disable the API keys after the semester has ended, so if you'd like to play around with your code after the term, you'll have to get your own API key.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d424f2a6-340a-4ef2-9722-dedd4198c631",
   "metadata": {},
   "source": [
    "# Question 6 - Set your API Key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "936c37f6-2ff9-4365-9314-21956a3ee6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "When writing code that will go to production (e.g. be seen by other people), \n",
    "you'll usually set your API key as an environment variable via your terminal.\n",
    "\"\"\"\n",
    "\n",
    "API_KEY = ... #Find the API key we've given you in EdStem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c6fc2f-66d4-40b0-86dd-84a8f2e0ad6c",
   "metadata": {},
   "source": [
    "# Question 7 â€“ Understanding the API Call\n",
    "## API Request Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecd63c2-dc23-4e47-ac96-677d6030a686",
   "metadata": {},
   "source": [
    "Let's start by taking a look at the [chat completion](https://platform.openai.com/docs/api-reference/chat/create) functionality of these Open AI models. As you can see, you can think of an API request as just a fancy function call."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091b2651-cbf2-4eaa-9f38-091590eb5e25",
   "metadata": {},
   "source": [
    "When making a chat completion request, what is the data type of `messages` (e.g. integer, boolean, etc)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabec3b9-33ce-40ad-b26a-9065a84786db",
   "metadata": {},
   "source": [
    "REPLACE THIS TEXT WITH YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a865de3-d453-4b41-a5db-8f08f814f7f3",
   "metadata": {},
   "source": [
    "When making a chat completion request, what is the data type of each element within `messages` (e.g. integer, boolean, etc)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876d61b5-1113-4eda-91f2-e169f51cca3b",
   "metadata": {},
   "source": [
    "REPLACE THIS TEXT WITH YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce24ccee-24a3-437c-b259-dfc584e8f198",
   "metadata": {},
   "source": [
    "What are four different valid Strings that can be supplied as arguments in the `role` parameter?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08f8c2f-2305-4b3d-8603-48d54d8ec32a",
   "metadata": {},
   "source": [
    "REPLACE THIS TEXT WITH YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33de9188-4cb6-4da1-810f-d8ecb11016ad",
   "metadata": {},
   "source": [
    "## API Request Return Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40e87c1-a37f-40aa-899a-3ea0aad912e5",
   "metadata": {},
   "source": [
    "At its heart, an API call to the OpenAI API just requires some choice of LLM to be supplied as an argument, as well as the message we want to send to the LLM. The model is a String, and the message is a list of dictionaries. Each dictionary contains a mapping of \"role\" to the corresponding role, and \"content\" to the actual message. Let's start by making our first API request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b6e3dde-b91d-4e6a-b9cf-ce66592fc3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key = API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6bf2896f-fc44-46d1-80ee-6cc3a5040da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = [\n",
    "    {\"role\": \"user\", \"content\": \"Hi there!\"} #We create a list of dictionaries containing the prompt.\n",
    "]\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\", #Picking the model \n",
    "  messages=message #Supplying the message\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43eb11ba-dca7-4c32-b327-394016cd2b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "openai.types.chat.chat_completion.ChatCompletion"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(completion) #Run this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c527b059-2e99-45b2-b70f-522640e74fa6",
   "metadata": {},
   "source": [
    "Notice that a [chat completion object](https://platform.openai.com/docs/api-reference/chat/object) is returned from the API call. \n",
    "\n",
    "We can then convert this into json so we can parse the outputs! Alternatively, the API reference also shows you how to access it via **dot notation**, which is not in scope for this course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d568da0-1fd1-40d3-b02d-294d54a9b0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "57119c9d-4a0f-4d66-89e0-285b853292b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_json = completion.json() \n",
    "response_dict = json.loads(response_json)\n",
    "type(response_dict) #Notice that this is a dictionary!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce349206-c0ea-47f2-be25-a3cba496584b",
   "metadata": {},
   "source": [
    "Super cool! We turned a chat completion object into a dictionary, which we know how to parse. Let's take a look inside the dictionary..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "730c2440-151f-4a9d-903b-59de931b83d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-AWsaS6BbyCpul7SPTcnTxIpqw5wLk',\n",
       " 'choices': [{'finish_reason': 'stop',\n",
       "   'index': 0,\n",
       "   'logprobs': None,\n",
       "   'message': {'content': 'Hello! How can I assist you today?',\n",
       "    'refusal': None,\n",
       "    'role': 'assistant',\n",
       "    'audio': None,\n",
       "    'function_call': None,\n",
       "    'tool_calls': None}}],\n",
       " 'created': 1732399692,\n",
       " 'model': 'gpt-4o-mini-2024-07-18',\n",
       " 'object': 'chat.completion',\n",
       " 'service_tier': None,\n",
       " 'system_fingerprint': 'fp_0705bf87c0',\n",
       " 'usage': {'completion_tokens': 9,\n",
       "  'prompt_tokens': 10,\n",
       "  'total_tokens': 19,\n",
       "  'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "   'audio_tokens': 0,\n",
       "   'reasoning_tokens': 0,\n",
       "   'rejected_prediction_tokens': 0},\n",
       "  'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a818c0-6169-418d-99b6-4327b739a17c",
   "metadata": {},
   "source": [
    "Given `response_dict`, write an expression that would evaluate to the response from the LLM (in this case, \"Hello! How can I assist you today?\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f38bd71-606d-41e2-bfe8-d95665aa0856",
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR EXPRESSION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e264bc1-357e-4782-9ac5-9af1a91e99f4",
   "metadata": {},
   "source": [
    "# Question 8 â€“ Making Your Own API Request!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82233dcc-fff5-41a2-a4c2-c946d36d14a5",
   "metadata": {},
   "source": [
    "Try modifying and making your own API request to see what the best restaurant in Berkeley is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cdea9674-b920-4fac-b01e-d5e97e6b6aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "While popularity can vary, one of the most well-known restaurants in Berkeley is Chez Panisse, famous for its role in the farm-to-table movement. Other popular spots include the Cheeseboard Collective and Gather.\n"
     ]
    }
   ],
   "source": [
    "#The system content allows us to specify external instructions to the model.\n",
    "message = [\n",
    "    {\"role\": \"system\", \"content\": \"Please keep your response brief.\"},\n",
    "    {\"role\": \"user\", \"content\": ...} #YOUR PROMPT HERE\n",
    "]\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\", #Picking model \n",
    "  messages=message #Supplying the message\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content) #Accesses the response from the model using dot notation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea05a95f-810b-474e-b191-bae1dbca732c",
   "metadata": {},
   "source": [
    "# Question 9 â€“ Creating A Helper Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f24ce9-94ef-48ad-9972-37a2ebad01d8",
   "metadata": {},
   "source": [
    "Since writing the same lines of code over and over can be cumbersome, let's write a utility function to help us make these API requests and process them.\n",
    "\n",
    "Fill in `prompt`, which takes in a String representing the model we want to use, as well as a list of dictionaries representing the message we want to send to the model. This function will return the message the LLM sends back to us, since we don't care about the other parts of the chat completion object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "157bc1e0-9e85-405f-af76-d030b078450a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt(model, message):\n",
    "    \"\"\"\n",
    "    Makes an API request to a LLM and returns the message.\n",
    "\n",
    "    Inputs:\n",
    "    model: A String representing the model we're using\n",
    "    message: A list of dictionaries, where each dictionary has two entries.\n",
    "    The first entry in each dictionary should have the key \"role\", and a value representing the role.\n",
    "    The second entry in each dictionary should have the key \"content\", and a value representing the content.\n",
    "\n",
    "    Returns:\n",
    "    A String representing the result of an API request to the model, parsed to just get the message back.\n",
    "\n",
    "    >>> model_choice = \"gpt-4o-mini\"\n",
    "    >>> message = [{\"role\": \"user\", \"content\": \"Hi there!\"}]\n",
    "    >>> prompt(model_choice, message)\n",
    "    'Hello! How can I assist you today?'\n",
    "    \"\"\"\n",
    "    pass    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7e5c2e9-499b-47d0-b5c8-9ea0151fc58d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m model_choice \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4o-mini\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m message \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHi there!\u001b[39m\u001b[38;5;124m\"\u001b[39m}]\n\u001b[0;32m----> 5\u001b[0m \u001b[43mprompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_choice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#Should show something along the lines of \"How can I assist you today?\"\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[18], line 19\u001b[0m, in \u001b[0;36mprompt\u001b[0;34m(model, message)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprompt\u001b[39m(model, message):\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m    Makes an API request to a LLM and returns the message.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m    'Hello! How can I assist you today?'\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m     completion \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     20\u001b[0m       model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     21\u001b[0m       messages\u001b[38;5;241m=\u001b[39mmessage\n\u001b[1;32m     22\u001b[0m     )\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m completion\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n",
      "\u001b[0;31mNameError\u001b[0m: name 'client' is not defined"
     ]
    }
   ],
   "source": [
    "#Test your implementation of prompt here\n",
    "\n",
    "model_choice = \"gpt-4o-mini\"\n",
    "message = [{\"role\": \"user\", \"content\": \"Hi there!\"}]\n",
    "prompt(model_choice, message) #Should show something along the lines of \"How can I assist you today?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bc2b97-32f6-4d22-ba72-6aac13dd7a5c",
   "metadata": {},
   "source": [
    "# Question 10 - Preparing the Model Context\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db74fde7-eb88-493c-a165-a0ffc157b7b0",
   "metadata": {},
   "source": [
    "## Model Context - Codebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cbe9d5-149b-4794-9624-76215d3e19b7",
   "metadata": {},
   "source": [
    "Now, let's attempt to use the gpt-4o-mini model to label all of our Tweets! To begin, take your codebook from Part 1 and turn it into a dictionary, with the Code as the key, and the description as a value. For instance, if we had the following codebook: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f884d62-b7bd-421d-b97f-49d15c6af9c6",
   "metadata": {},
   "source": [
    "| General Category    | Description                                       | Values                          | Code |\n",
    "|---------------------|---------------------------------------------------|---------------------------------|------|\n",
    "| **Emotion**         | Expresses happiness or generally positive emotion. | Happiness                      | EM-H |\n",
    "|                     | Expresses a feeling of sorrow or unhappiness.      | Sadness                        | EM-S |\n",
    "|                     | Expresses a feeling of displeasure or rage.        | Anger                          | EM-A |\n",
    "|                     | Expresses astonishment or unexpected reaction.     | Surprise                       | EM-SP |\n",
    "|                     | Expresses fear or anxiety.                         | Fear                           | EM-F |\n",
    "| **Intensity**       | Indicates a low amount of emotional strength.        | Low                            | IN-L |\n",
    "|                     | Indicates a moderate level of emotional strength.  | Medium                         | IN-M |\n",
    "|                     | Indicates a strong emotional reaction.             | High                           | IN-H |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e36c3a-203c-40eb-a26b-c5a019a3d866",
   "metadata": {},
   "source": [
    "That would turn into the following dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "09ec9693-9505-4ce6-b8e0-634771adf4d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EM-H': 'Expresses happiness or generally positive emotion.',\n",
       " 'EM-S': 'Expresses a feeling of sorrow or unhappiness.',\n",
       " 'EM-A': 'Expresses a feeling of displeasure or rage.',\n",
       " 'EM-SP': 'Expresses astonishment or unexpected reaction.',\n",
       " 'EM-F': 'Expresses fear or anxiety.',\n",
       " 'IN-L': 'Indicates a low amount of emotional strength.',\n",
       " 'IN-M': 'Indicates a moderate level of emotional strength.',\n",
       " 'IN-H': 'Indicates a strong emotional reaction.'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_codebook = {\n",
    "    \"EM-H\": \"Expresses happiness or generally positive emotion.\",\n",
    "    \"EM-S\": \"Expresses a feeling of sorrow or unhappiness.\",\n",
    "    \"EM-A\": \"Expresses a feeling of displeasure or rage.\",\n",
    "    \"EM-SP\": \"Expresses astonishment or unexpected reaction.\",\n",
    "    \"EM-F\": \"Expresses fear or anxiety.\",\n",
    "\n",
    "    \"IN-L\": \"Indicates a low amount of emotional strength.\",\n",
    "    \"IN-M\": \"Indicates a moderate level of emotional strength.\",\n",
    "    \"IN-H\": \"Indicates a strong emotional reaction.\"\n",
    "}\n",
    "example_codebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8de9d20-cece-48d6-b7de-4b5a67440bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Ellipsis}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PUT YOUR CODEBOOK AS A DICTIONARY HERE\n",
    "codebook = {\n",
    "    ...\n",
    "}\n",
    "codebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe5a74d-73e0-4014-9171-eecb325a8e02",
   "metadata": {},
   "source": [
    "# Question 11 â€“ Developing our prompt\n",
    "Now that you've gotten a chance to turn your codebook into a dictionary (which can be type casted into a String), try using `prompt` to have \"gpt-4o-mini\" code your 20 Tweets in the `hand_coded_dataset`! Once you've done so, add this to your `hand_coded_dataset`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8bfbbf-c7b2-453c-8dd8-817c7532b41c",
   "metadata": {},
   "source": [
    "## First Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bb30247d-23a8-4e05-a316-a992d4e6aa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_coded_responses = make_array()\n",
    "\n",
    "... #YOUR CODE HERE\n",
    "\n",
    "hand_coded_dataset = hand_coded_dataset.with_column(\"LLM response 1\", model_coded_responses)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f4a968ab-5722-49b2-a7db-555aa4c1273c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>airline</th> <th>name</th> <th>retweet_count</th> <th>text</th> <th>user_timezone</th> <th>Jedi Codes</th> <th>LLM response 1</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>US Airways    </td> <td>rossj987       </td> <td>0            </td> <td>@USAirways sorry doesn't help.  It's midnight PST.  How  ...</td> <td>Eastern Time (US & Canada)</td> <td>EM-A IN-H </td> <td>EM-A: Expresses a feeling of displeasure or rage.           </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>American      </td> <td>JR_Fett        </td> <td>0            </td> <td>@AmericanAir Well I'm showing I am still sitting at the  ...</td> <td>nan                       </td> <td>IN-L      </td> <td>EM-A                                                        </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>United        </td> <td>8629Fissile    </td> <td>0            </td> <td>@united Okay thank you                                      </td> <td>London                    </td> <td>EM-H IN-L </td> <td>EM-H                                                        </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>American      </td> <td>ransvoice      </td> <td>0            </td> <td>@AmericanAir Would have had to fly real far south, huh?  ...</td> <td>Eastern Time (US & Canada)</td> <td>nan       </td> <td>EM-F                                                        </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Virgin America</td> <td>wmrrock        </td> <td>0            </td> <td>@VirginAmerica got it. All set - Thanks!                    </td> <td>Eastern Time (US & Canada)</td> <td>nan       </td> <td>EM-H                                                        </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>United        </td> <td>NonYourBusines9</td> <td>0            </td> <td>@united I left my comment with customer care. Thanks for ...</td> <td>nan                       </td> <td>nan       </td> <td>IN-L                                                        </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>United        </td> <td>Eivind_G       </td> <td>0            </td> <td>@united Then you delete my return ticket to Europe and b ...</td> <td>nan                       </td> <td>nan       </td> <td>EM-A, IN-H                                                  </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Southwest     </td> <td>DeniseMarois   </td> <td>0            </td> <td>@SouthwestAir Feeling very frustrated that I bought WIFI ...</td> <td>nan                       </td> <td>nan       </td> <td>EM-A, IN-H                                                  </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Southwest     </td> <td>jodyfuller     </td> <td>0            </td> <td>@SouthwestAir, thanks for being so good to us #military  ...</td> <td>Central Time (US & Canada)</td> <td>nan       </td> <td>EM-H                                                        </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>United        </td> <td>dizbaa1        </td> <td>0            </td> <td>@united @JedediahBila KP I am not traveling - we trying  ...</td> <td>Eastern Time (US & Canada)</td> <td>nan       </td> <td>EM-H                                                        </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>United        </td> <td>JerseyRic      </td> <td>0            </td> <td>@united  RES # 0167560070877     Fsqthg   Thanks            </td> <td>Eastern Time (US & Canada)</td> <td>nan       </td> <td>EM-H                                                        </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Virgin America</td> <td>finslippy      </td> <td>0            </td> <td>@VirginAmerica got a flight (we were told) for 4:50 toda ...</td> <td>Eastern Time (US & Canada)</td> <td>nan       </td> <td>{'EM-A': 'Expresses a feeling of displeasure or rage.',  ...</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>US Airways    </td> <td>clarkhook      </td> <td>0            </td> <td>@USAirways Seriously. You can't tweet and let people kno ...</td> <td>Eastern Time (US & Canada)</td> <td>nan       </td> <td>EM-A: Expresses a feeling of displeasure or rage.           </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Southwest     </td> <td>TravelWithSuze </td> <td>0            </td> <td>@SouthwestAir flight yesterday Cancelled Flighted. Got t ...</td> <td>nan                       </td> <td>nan       </td> <td>EM-A                                                        </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>United        </td> <td>tarlonious     </td> <td>0            </td> <td>@united and waiting                                         </td> <td>nan                       </td> <td>nan       </td> <td>EM-H                                                        </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>United        </td> <td>AngelikaGiatras</td> <td>0            </td> <td>@united can anyone assure me that the aircraft coming to ...</td> <td>Eastern Time (US & Canada)</td> <td>nan       </td> <td>EM-F                                                        </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>United        </td> <td>PaulBEsteves   </td> <td>0            </td> <td>@united thanks for the help. Wish the phone reps could b ...</td> <td>Eastern Time (US & Canada)</td> <td>nan       </td> <td>EM-H                                                        </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Southwest     </td> <td>sgodsay        </td> <td>0            </td> <td>@SouthwestAir can you provide direct assistance? My coll ...</td> <td>Quito                     </td> <td>nan       </td> <td>IN-M: Indicates a moderate level of emotional strength.     </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Southwest     </td> <td>MFarrell21     </td> <td>0            </td> <td>@SouthwestAir understand you can only do so much but oft ...</td> <td>Eastern Time (US & Canada)</td> <td>nan       </td> <td>EM-A                                                        </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Delta         </td> <td>leighericam    </td> <td>0            </td> <td>@JetBlue are yall going bankrupt or is inflation just re ...</td> <td>nan                       </td> <td>nan       </td> <td>EM-A, IN-H                                                  </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hand_coded_dataset.show(20) #Run this to compare your hand-coded responses with the LLM response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e84147-a074-4dae-81f7-902a8ad5cdad",
   "metadata": {},
   "source": [
    "Are there any differences between how you coded your responses and how the model coded the responses? What about the formatting of the codes? 2-3 sentence should be sufficient here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8148f2-605a-4bef-bde9-d95b2452ad8a",
   "metadata": {},
   "source": [
    "REPLACE THIS TEXT WITH YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509fcfb1-59b5-415b-aab6-060757374672",
   "metadata": {},
   "source": [
    "# Question 11 â€“ Prompt Engineering\n",
    "Let's make sure that our prompt has a bit more structure to it as well. \n",
    "\n",
    "1. Follow the [LLM prompting guidelines](https://direct.mit.edu/view-large/figure/4722326/coli_a_00502_i004.tif) to make your prompt better!\n",
    "2. Then, read over the [Open AI guide](https://platform.openai.com/docs/guides/prompt-engineering#tactic-provide-examples) on how to do few-shot prompting.\n",
    "\n",
    "Your updated prompt should:\n",
    "1. Include a brief context (15 words or less) \n",
    "2. Enumerate options as alphabetical multiple choice, separated by a new line. For this, you can include the newline character \"\\n\" in your prompt.\n",
    "3. Specify constraints\n",
    "4. Specify actions under uncertainty\n",
    "5. Provide 2 examples of expected inputs and outputs\n",
    "\n",
    "Use this to add a new column, `LLM response 2`, to the `hand_coded_dataset` Table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ed868427-6881-4692-ac57-3af1c7e4253c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Column length mismatch. New column does not have the same number of rows as table.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m model_coded_responses \u001b[38;5;241m=\u001b[39m make_array()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#Isabella and Kenneth, can you send me your updated prompts?\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m hand_coded_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mhand_coded_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_column\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLLM response 2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_coded_responses\u001b[49m\u001b[43m)\u001b[49m    \n",
      "File \u001b[0;32m/srv/conda/lib/python3.11/site-packages/datascience/tables.py:2500\u001b[0m, in \u001b[0;36mTable.with_column\u001b[0;34m(self, label, values, formatter)\u001b[0m\n\u001b[1;32m   2498\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(formatter, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m   2499\u001b[0m     formatter \u001b[38;5;241m=\u001b[39m formatter[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformatter\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m-> 2500\u001b[0m \u001b[43mnew_table\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2501\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_table\n",
      "File \u001b[0;32m/srv/conda/lib/python3.11/site-packages/datascience/tables.py:991\u001b[0m, in \u001b[0;36mTable.append_column\u001b[0;34m(self, label, values, formatter)\u001b[0m\n\u001b[1;32m    988\u001b[0m         values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mtuple\u001b[39m(values))\n\u001b[1;32m    990\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_rows \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(values) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_rows:\n\u001b[0;32m--> 991\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mColumn length mismatch. New column does not have \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    992\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe same number of rows as table.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    993\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    994\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(values)\n",
      "\u001b[0;31mValueError\u001b[0m: Column length mismatch. New column does not have the same number of rows as table."
     ]
    }
   ],
   "source": [
    "model_coded_responses = make_array()\n",
    "\n",
    "#Isabella and Kenneth, can you send me your updated prompts?\n",
    "\n",
    "hand_coded_dataset = hand_coded_dataset.with_column(\"LLM response 2\", model_coded_responses)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db792fc0-acb6-47ec-a8c9-90d37cac0f02",
   "metadata": {},
   "source": [
    "Are there any differences between how you coded your responses and how the model coded the responses? What about the formatting of the codes? 2-3 sentence should be sufficient here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b13b628-28bb-499e-9326-d370c89da1a6",
   "metadata": {},
   "source": [
    "REPLACE THIS TEXT WITH YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1b3e30-d43d-474a-83f5-9bc663bee2bd",
   "metadata": {},
   "source": [
    "# Question 12 â€“ Coding the Full Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5fa6e4-e6e2-45be-9530-8f0cbbd457fb",
   "metadata": {},
   "source": [
    "Once you're satisfied with your prompt and how your LLM is performing, use that same prompt to code the entire `full_dataset`. We've provided a progress checking library so you can see how long it will take (warning: it will likely take ~7 minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "50da8b18-f631-4511-b06b-a35447876cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944fc954-f55a-4b1c-a0c6-1ece7e064141",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_coded_responses = []\n",
    "\n",
    "for text in tqdm(full_dataset.column(...), desc=\"Processing texts\"): #Put your column name here\n",
    "    message = [\n",
    "        ...\n",
    "    ]\n",
    "    llm_response = prompt(\"gpt-4o-mini\", message)\n",
    "    model_coded_responses.append(llm_response)\n",
    "\n",
    "# Add the responses to the dataset\n",
    "full_dataset = full_dataset.with_column(\"LLM codes\", model_coded_responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc3566b-7f07-4270-89f9-6e1fa33e9a34",
   "metadata": {},
   "source": [
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "\n",
    "# Section 3: Visualizations and Results\n",
    "\n",
    "<br></br>\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "# Question 12 â€“ Exploring Your Findings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c0c55b-342c-40f2-9177-34cb376cb1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "I'll have each of you do the following:\n",
    "\n",
    "1. Try coding the full dataset using the prompt from Question 10 as well (with no prompt engineering).\n",
    "2. Generate some visualizations comparing the codes applied with and without prompt engineering.\n",
    "\n",
    "1. Compare the codes applied with the results Question 12\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8022483-8192-40a0-ad98-ad3744f7d78c",
   "metadata": {},
   "source": [
    "In other words, given your CSS concept, develop a codebook that you'd like to classify the text with. When developing a codebook, it can be helpful to read through some of the data before creating your values. Your codebook should have the same 4 column titles as the codebook above. Your codebook can have anywhere from 3-10 codes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf431b3-f37f-4189-a496-d95bf99c73f1",
   "metadata": {},
   "source": [
    "PUT YOUR INITIAL CODEBOOK HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a3c9ac-9759-48fb-8d1c-a987b6834a1b",
   "metadata": {},
   "source": [
    "# Submission\n",
    "\n",
    "Once you're done, go to File --> Save and Export Notebook as --> PDF, and submit to Gradescope! Congrats on finishing Part 1 of the Final Project!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
